{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c3ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import hyperopt\n",
    "except ModuleNotFoundError:\n",
    "    !pip install hyperopt\n",
    "try:\n",
    "    import BanditOpt\n",
    "except ModuleNotFoundError:\n",
    "    !pip install BO4ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70641b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from BanditOpt.BO4ML import ConfigSpace, ConditionalSpace, AlgorithmChoice, CategoricalParam, IntegerParam, FloatParam, Forbidden\n",
    "from BanditOpt.BO4ML import BO4ML\n",
    "from hyperopt import STATUS_OK, STATUS_FAIL\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e252c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import imblearn\n",
    "except ModuleNotFoundError:\n",
    "    !pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from imblearn.under_sampling import NearMiss, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2595c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Space\n",
    "search_space = ConfigSpace()\n",
    "\n",
    "#random_seed uses for all operators\n",
    "random_seed=CategoricalParam(seed,\"random_state\")\n",
    "#1st Operator: Resampling technique\n",
    "smo_type = AlgorithmChoice([['NO'], ['SMOTE', 'BorderlineSMOTE']\n",
    "            , ['SMOTEENN', 'SMOTETomek'],['NearMiss', 'TomekLinks']], 'resampler')\n",
    "\n",
    "#2nd Operator: Classifier\n",
    "alg_namestr = AlgorithmChoice([\"SVM\", \"RF\"], \"alg_namestr\")\n",
    "# Define Search Space for Support Vector Machine\n",
    "kernel = CategoricalParam([\"linear\", \"rbf\", \"poly\", \"sigmoid\"], \"kernel\")\n",
    "C = FloatParam([1e-2, 100], \"C\")\n",
    "degree = IntegerParam([1, 5], 'degree')\n",
    "coef0 = FloatParam([0.0, 10.0], 'coef0')\n",
    "gamma = FloatParam([0, 20], 'gamma')\n",
    "# Define Search Space for Random Forest\n",
    "n_estimators = IntegerParam([5, 100], \"n_estimators\")\n",
    "criterion = CategoricalParam([\"gini\", \"entropy\"], \"criterion\")\n",
    "max_depth = IntegerParam([10, 200], \"max_depth\")\n",
    "max_features = CategoricalParam(['auto', 'sqrt', 'log2'], \"max_features\")\n",
    "# Add Search space to Configuraion Space\n",
    "search_space.add_multiparameter([random_seed,smo_type,alg_namestr, kernel, C, degree, coef0, gamma\n",
    "                                    , n_estimators, criterion, max_depth, max_features])\n",
    "# Define conditional Space\n",
    "con = ConditionalSpace(\"conditional\")\n",
    "con.addMutilConditional([kernel, C, degree, coef0, gamma,random_seed], alg_namestr, \"SVM\")\n",
    "con.addMutilConditional([n_estimators, criterion, max_depth, max_features,random_seed], alg_namestr, [\"RF\"])\n",
    "con.addMutilConditional([random_seed],smo_type,['SMOTE', 'BorderlineSMOTE','SMOTEENN', 'SMOTETomek'])\n",
    "# Define infeasible space (if any)\n",
    "#forb = Forbidden()\n",
    "#forb.addForbidden(abc,[\"A\",\"C\",\"D\"],alg_namestr,\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b99ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def obj_func(params):    \n",
    "    global X,y, prefix, seed,iteration  \n",
    "    iteration+=1\n",
    "    params = {k: params[k] for k in params if params[k]}\n",
    "    \n",
    "    rparams = params.pop('resampler')\n",
    "    resampler=rparams.pop(prefix)\n",
    "    if (resampler == 'SMOTE'):\n",
    "        smo = SMOTE(**rparams)\n",
    "    elif (resampler == 'BorderlineSMOTE'):\n",
    "        smo = BorderlineSMOTE(**rparams)\n",
    "    elif (resampler == 'BorderlineSMOTE'):\n",
    "        smo = BorderlineSMOTE(**rparams)\n",
    "    elif (resampler == 'SMOTEENN'):\n",
    "        smo = SMOTEENN(**rparams)\n",
    "    elif (resampler == 'SMOTETomek'):\n",
    "        smo = SMOTETomek(**rparams)\n",
    "    elif (resampler == 'NearMiss'):\n",
    "        smo = NearMiss(**rparams)\n",
    "    elif (resampler == 'TomekLinks'):\n",
    "        smo = TomekLinks(**rparams)\n",
    "    \n",
    "    cparams = params['alg_namestr']\n",
    "    params.pop(\"alg_namestr\", None)  \n",
    "    classifier=cparams.pop('name')\n",
    "    if (classifier == 'SVM'):\n",
    "        clf = SVC(**params, random_state=seed)\n",
    "    elif (classifier == 'RF'):\n",
    "        clf = RandomForestClassifier(**params, random_state=seed)    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    if (resampler== \"NO\"):\n",
    "            X_smo_train, y_smo_train=X_train, y_train\n",
    "    else:\n",
    "        X_smo_train, y_smo_train=smo.fit_resample(X_train, y_train)\n",
    "    y_test_pred = clf.fit(X_smo_train, y_smo_train).predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_test,y_test_pred)\n",
    "    print('..iteration:',iteration,' -- accuracy_score', score)\n",
    "    return {'loss':-score, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9b7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====INIT: 10\n",
      "=== 2 === 2\n",
      "..iteration: 1  -- accuracy_score 1.0\n",
      "..iteration: 2  -- accuracy_score 1.0\n",
      "=== 5 === 1\n",
      "..iteration: 3  -- accuracy_score 0.9666666666666667\n",
      "=== 6 === 1\n",
      "..iteration: 4  -- accuracy_score 0.8666666666666667\n",
      "=== 4 === 1\n",
      "..iteration: 5  -- accuracy_score 0.9333333333333333\n",
      "=== 0 === 1\n",
      "..iteration: 6  -- accuracy_score 0.9666666666666667\n",
      "=== 3 === 2\n",
      "..iteration: 7  -- accuracy_score 1.0\n",
      "..iteration: 8  -- accuracy_score 0.9666666666666667\n",
      "=== 1 === 1\n",
      "..iteration: 9  -- accuracy_score 0.9666666666666667\n",
      "=== 7 === 1\n",
      "..iteration: 10  -- accuracy_score 1.0\n",
      "END Random search on  8  combinations\n",
      "..iteration: 11  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 12  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 13  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 14  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 15  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 16  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 17  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 18  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 19  -- accuracy_score 1.0\n",
      "..iteration: 20  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 21  -- accuracy_score 0.8333333333333334\n",
      "..iteration: 22  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 23  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 24  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 25  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 26  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 27  -- accuracy_score 1.0\n",
      "..iteration: 28  -- accuracy_score 0.9\n",
      "..iteration: 29  -- accuracy_score 0.9\n",
      "..iteration: 30  -- accuracy_score 1.0\n",
      "..iteration: 31  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 32  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 33  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 34  -- accuracy_score 1.0\n",
      "..iteration: 35  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 36  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 37  -- accuracy_score 1.0\n",
      "..iteration: 38  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 39  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 40  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 41  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 42  -- accuracy_score 0.9333333333333333\n",
      "..iteration: 43  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 44  -- accuracy_score 1.0\n",
      "..iteration: 45  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 46  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 47  -- accuracy_score 1.0\n",
      "..iteration: 48  -- accuracy_score 0.9666666666666667\n",
      "..iteration: 49  -- accuracy_score 1.0\n",
      "..iteration: 50  -- accuracy_score 0.9333333333333333\n",
      "=== best param: {'alg_namestr': {'C': 9.066114224579216, 'coef0': 5.782233008102185, 'degree': 3, 'gamma': 4.677684662224529, 'kernel': 'sigmoid', 'name': 'SVM', 'random_state': 1}, 'resampler': {'name': 'SMOTEENN', 'random_state': 1}}\n",
      "=== Best accuracy_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Load iris data\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "### Optimizing ...\n",
    "prefix='name'\n",
    "seed=1\n",
    "iteration=0\n",
    "opt = BO4ML(search_space, obj_func, \n",
    "            conditional=con, #conditional \n",
    "            isFair=True,\n",
    "            #forbidden=forb, #No infeasible space defined in this example\n",
    "            HPOopitmizer='hpo', #use hyperopt\n",
    "            max_eval=50, verbose=True, #number of evaluations\n",
    "            n_init_sample=10, #number of init sample \n",
    "            hpo_algo=\"tpe\", #tpe, rand, atpe, anneal\n",
    "            SearchType=\"full\",# set \"full\" to use our sampling approach. Otherwise, the original library to be used\n",
    "            random_seed=seed,hpo_prefix=prefix,\n",
    "            ifAllSolution=True\n",
    "            )\n",
    "best_param, min_value, listofTrial, eval_count = opt.run()\n",
    "print('=== best param:',best_param)\n",
    "print('=== Best accuracy_score:',-min_value)\n",
    "#listofTrial: see hyperopt document for ``trails''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
